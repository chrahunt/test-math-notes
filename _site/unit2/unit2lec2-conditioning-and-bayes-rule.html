<!DOCTYPE html>
<head>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      extensions: [
        "AMSmath.js",
        "AMSsymbols.js",
        "noErrors.js",
        "noUndefined.js"
      ]
    },
    jax: [
      "input/TeX",
      "output/HTML-CSS"
    ],
    tex2jax: {
      inlineMath: [ ['$','$'], ['\(', '\)'] ],
      displayMath: [ ['\[','\]'] ],
    }
  });
</script>
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


</head>
<body>
<div class="container">
  <h1 id="lec-2-conditioning-and-bayes-rule">Lec 2: Conditioning and Baye’s rule</h1>

<p>$\newcommand{\pr}[1]{\mathbf{P}!\left(#1\right)}$
$\newcommand{\cpr}[2]{\mathbf{P}!\left(#1\,\middle|\,#2\right)}$</p>

<h2 id="motivation-and-overview">Motivation and Overview</h2>

<p>Conditional probabilities are useful for:<br />
breaking up complex models, divide and conquer</p>

<p>What forms the foundation of the field of inference?<br />
Conditional probabilities</p>

<p>When is independence useful?<br />
When probabilistic phenomena are non-interacting</p>

<p>Terms:
1. <strong>conditioning</strong>
2. <strong>independence</strong></p>

<p>Conditional probability
* Definition
* Motivation</p>

<p>Three tools that use conditional probability
* Multiplication rule
* Total probability theorem
* Bayes rule especially</p>

<p>These tools contain very powerful ideas.</p>

<p>Which rule is the foundation for the field of inference?<br />
Bayes rule</p>

<p>What is the definition of conditional probability?
[
\cpr{A}{B} = \frac{\pr{A \cap B}}{\pr{B}}
]
given $\pr{B} \neq 0$</p>

<p>What motivates our definition of conditional probability?<br />
Given a set of outcomes in $B$ with certain probability, the set of outcomes in $A$ that are also in $B$ over the total probability of outcomes in $B$ puts the probability of outcomes in $A$ in terms of the total probability of outcomes in $B$ (which includes outcomes not in $A$).</p>

<h2 id="dice-roll-example">Dice roll example</h2>

<p>showing intersection of cases:</p>

<p>Suppose we have 2 4-sided die. The outcomes are X and Y.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>A := min(X, Y) = 2
B := max(X, Y) = 3
</code></pre>
</div>

<p>[
\cpr{B}{A} = \frac{\pr{B\cap A}}{\pr{A}}
]</p>

<h2 id="conditional-probabilities-obey-probability-axioms">Conditional probabilities obey probability axioms</h2>

<p>Recall:
* Nonnegative
* Normalization
* Additivity of unions</p>

<p>Since conditional probabilities satisfy the probability axioms we can use probability theorems and formulas derived on normal probabilities on conditional probabilities.</p>

<p>What are conditional probabilities used for?<br />
Revising a model when we get new information.</p>

<p>Ex: Radar detection.</p>

<ul>
  <li>$A$ - airplane flying above</li>
  <li>$B$ - something registered on radar</li>
</ul>

<p><img src="unit2lec2-conditioning-and-bayes-rule\e8b6d820f52007d53b7a924c5d596ba4.png" alt="radar probability tree" /></p>

<p>The probabilities on the second level of the tree are conditional probabilities, meaning they already take into account the fact that $A$ or $A^c$ occurred.</p>

<p>What is the question here?<br />
$\pr{A\cap B}$, that something is flying and registered on radar.</p>

<p>Starting with the definition of conditional probability</p>

<p>[
\begin{align}
\cpr{B}{A} &amp;= \frac{\pr{A\cap B}}{\pr{A}}<br />
\pr{A} \cdot \cpr{B}{A} &amp;= \pr{A\cap B}<br />
0.05 \cdot 0.99 &amp;=
\end{align}
]</p>

<p>Total probability of something occurring: “the radar sees something”
[
\begin{align}
\pr{B} &amp;= \pr{A \cap B} + \pr{A^c \cap B}<br />
&amp;= 0.05 \cdot 0.99 + 0.95 \cdot 0.1<br />
&amp;= 0.1445
\end{align}
]</p>

<p>Reversed conditional probability: “if the radar registers something, what is the probability that it was because there was an airplane?”</p>

<p>[
\begin{align}
\cpr{A}{B} &amp;= \frac{\pr{A \cap B}}{\pr{B}}<br />
&amp;= \frac{0.05 \cdot 0.99}{0.1445}<br />
&amp;= 0.34
\end{align}
]</p>

<h2 id="multiplication-rule">Multiplication rule</h2>

<p>Motivation: Probability of dependent events.</p>

<p>$\cpr{A}{B} = \frac{\pr{A \cap B}}{\pr{B}}$</p>

<p>[
\begin{align}
\pr{A \cap B} &amp;= \pr{B} \cpr{A}{B}<br />
&amp;= \pr{A}\cpr{B}{A}
\end{align}
]</p>

<p>By association, it’s not difficult to come up with the same rule for three probabilities ($\cpr{A}{B, C}$. Thinking about it in terms of a tree as in the last example, this is calculating the individual leaf nodes along some tree</p>

<p>The general formula is</p>

<p>[
\pr{A_1 \cap A_2 \cap \cdots \cap A_n} = \pr{A_1} \prod_i \cpr{A_i}{A_1 \cap \cdots \cap A_{i-1}}
]</p>

<h2 id="total-probability-theorem">Total probability theorem</h2>

<p><img src="unit2lec2-conditioning-and-bayes-rule\0b6af1e49dd25ed3d1976c915ecd48c4.png" alt="total probability theorem derivation" /></p>

<h2 id="bayes-rule">Bayes Rule</h2>

<p>[
\cpr{A_i}{B} = \frac{\pr{A_i} \cpr{B}{A_i}}{\sum_j \pr{A_j} \cpr{B}{A_j}}
]</p>

<p>Imagine being given probabilities as in the radar example. They are provided with likelihood of sensing and then likelihood of true/false positive/negative. So the most straightforward question is, given that there’s an airplane, what’s the probability that it is sensed. Bayes rule answers the reverse of the straightforward question. Given that something was sensed, what’s the probability that an airplane is flying.</p>

<p>[
\frac{\text{weighted probability of $B$ occurring under $A_i$}}{\text{total probability of $B$ in any situation}}
]</p>

<p>So given that $B$ occurred, the probability that $A_i$ occurred is the intersection of $A_i$ and $B$ over the total probability given in $B$.</p>

<p>These are all ways to work with information when you have an incomplete picture, or because it doesn’t make sense to enumerate every possible combination of things you may want to know.</p>

<p>Forms the foundation of Bayesian inference which allows us to update our beliefs as new evidence comes in.</p>


</div>
</body>
</html>
